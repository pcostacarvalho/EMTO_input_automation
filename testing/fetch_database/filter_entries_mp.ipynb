{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb04f1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pamco116/miniconda3/envs/repo_env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mp_api.client import MPRester\n",
    "import json\n",
    "\n",
    "# Replace with your actual API key\n",
    "API_KEY = \"vhdPJ1STyEi4znoIbrdg6s1j2Q03BQdH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a488885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ICSD entries\n",
    "with open('full_icsd_entries.txt', 'r') as f:\n",
    "    icsd_entries = [line.strip() for line in f]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "882865fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of experimental structures: 135468\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of experimental structures: {len(icsd_entries)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bcccd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 49283/49283 [00:10<00:00, 4809.23it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build ICSD to MP mapping\n",
    "with MPRester(API_KEY) as mpr:\n",
    "    mp_docs = mpr.materials.summary.search(        \n",
    "        theoretical=False,\n",
    "        fields=[\"database_IDs\", \"material_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a72596a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build ICSD to MP mapping\n",
    "with MPRester(API_KEY) as mpr:\n",
    "\n",
    "    icsd_to_mpid = {}\n",
    "    for mp_doc in mp_docs:\n",
    "        mpid = str(mp_doc.material_id)\n",
    "        for icsd_id in mp_doc.database_IDs.get(\"icsd\", []):\n",
    "            if icsd_id not in icsd_to_mpid:\n",
    "                id = icsd_id.replace('icsd-','').zfill(6)\n",
    "                icsd_to_mpid[id] = []\n",
    "            icsd_to_mpid[id].append(mpid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a48095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found in MP: 67372\n",
      "Not found: 68096\n"
     ]
    }
   ],
   "source": [
    "# Find matches\n",
    "found = []\n",
    "not_found = []\n",
    "\n",
    "for icsd in icsd_entries:\n",
    "    if icsd in icsd_to_mpid:\n",
    "        found.append((icsd, icsd_to_mpid[icsd]))\n",
    "    else:\n",
    "        not_found.append(icsd)\n",
    "\n",
    "# Save results\n",
    "with open('mp_found.txt', 'w') as f:\n",
    "    for icsd, mpids in found:\n",
    "        f.write(f\"{icsd}: {','.join(mpids)}\\n\")\n",
    "\n",
    "with open('mp_full_icsd.txt', 'w') as f:\n",
    "    for icsd, mpids in icsd_to_mpid.items():\n",
    "        f.write(f\"{icsd}: {','.join(mpids)}\\n\")\n",
    "\n",
    "\n",
    "print(f\"Found in MP: {len(found)}\")\n",
    "print(f\"Not found: {len(not_found)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c09ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Invert the dictionary - use ONLY found entries\n",
    "mpid_to_icsd = {}\n",
    "for icsd_id, mp_ids in found:\n",
    "    for mp_id in mp_ids:\n",
    "        if mp_id not in mpid_to_icsd:\n",
    "            mpid_to_icsd[mp_id] = []\n",
    "        mpid_to_icsd[mp_id].append(icsd_id)\n",
    "\n",
    "# Filter for MP IDs with only one ICSD entry\n",
    "filtered_mpid_to_icsd = {\n",
    "    mp_id: icsd_ids \n",
    "    for mp_id, icsd_ids in mpid_to_icsd.items() \n",
    "    if len(icsd_ids) == 1\n",
    "}\n",
    "\n",
    "# Save results\n",
    "with open('only_one_entry.txt', 'w') as f:\n",
    "    for mpids, icsd in filtered_mpid_to_icsd.items():\n",
    "        f.write(f\"{mpids}: {icsd[0]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b0b54d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered structures with only 1 ICSD entry: 28951\n"
     ]
    }
   ],
   "source": [
    "print(f'Filtered structures with only 1 ICSD entry: {len(filtered_mpid_to_icsd)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cfea30",
   "metadata": {},
   "source": [
    "# Parsing the theoretical structures from Materials Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd933bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 49283/49283 [00:48<00:00, 1016.71it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with MPRester(API_KEY) as mpr:\n",
    "    # Get structures for ICSD IDs\n",
    "    docs = mpr.materials.summary.search(\n",
    "        theoretical=False,\n",
    "        fields=[\"material_id\", \"database_IDs\", \"structure\", 'nsites', \n",
    "                'elements', 'nelements', 'composition', 'composition_reduced', \n",
    "                'formula_pretty', 'formula_anonymous', 'chemsys', 'volume', 'density', \n",
    "                'density_atomic', 'symmetry', 'origins', 'task_ids', 'formation_energy_per_atom', \n",
    "                'is_stable', 'band_gap', 'cbm', 'vbm', 'efermi', 'is_gap_direct', 'is_metal', \n",
    "                 'is_magnetic', 'ordering', 'total_magnetization', \n",
    "                 'theoretical'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ce2c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_icsd = [i[0] for i in filtered_mpid_to_icsd.values()]\n",
    "\n",
    "with open('icsd_structures.json', 'r') as f:\n",
    "    experimental = json.load(f)\n",
    "\n",
    "with MPRester(API_KEY) as mpr:\n",
    "\n",
    "    selected_docs = {}\n",
    "    for doc in docs:\n",
    "        for icsd_id in doc.database_IDs.get(\"icsd\", []):\n",
    "            id = icsd_id.replace('icsd-','').zfill(6)\n",
    "\n",
    "            if id in selected_icsd:\n",
    "                selected_docs[id] = {'MP': {}, 'ICSD': {}}\n",
    "                selected_docs[id]['MP'] = doc\n",
    "                selected_docs[id]['ICSD'] = experimental[id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "240219a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Collect structure origin task_ids\n",
    "structure_task_ids = []\n",
    "for icsd_id, data in selected_docs.items():\n",
    "    for origin in data['MP'].origins:\n",
    "        if origin.name == 'structure':\n",
    "            structure_task_ids.append(origin.task_id)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc543fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n1/wvc_v9ys04l707s_zw21wcw00000gn/T/ipykernel_11051/1271291504.py:8: DeprecationWarning: Accessing tasks data through MPRester.tasks is deprecated. Please use MPRester.materials.tasks instead.\n",
      "  task_docs = mpr.tasks.search(\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 11650844.44it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 13107200.00it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 17772474.58it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 19972876.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 18558867.26it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 19418074.07it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 482/482 [00:00<00:00, 19253852.65it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 499/499 [00:00<00:00, 20722353.43it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 7913781.13it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 20971520.00it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 16777216.00it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 19972876.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 23831272.73it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 20763881.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 18558867.26it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 18558867.26it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 21620123.71it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 16513007.87it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 22795130.43it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 477/477 [00:00<00:00, 16399041.05it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 21845333.33it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 22550021.51it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 492/492 [00:00<00:00, 19467901.58it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 499/499 [00:00<00:00, 19932930.44it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 497/497 [00:00<00:00, 19853038.93it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 495/495 [00:00<00:00, 19963273.85it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 496/496 [00:00<00:00, 20003603.69it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 21183353.54it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 23831272.73it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 19239926.61it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 14665398.60it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 491/491 [00:00<00:00, 20594032.64it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 17189770.49it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 493/493 [00:00<00:00, 18462427.43it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 498/498 [00:00<00:00, 22459821.42it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 20763881.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 499/499 [00:00<00:00, 20124593.23it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 491/491 [00:00<00:00, 18224807.65it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 499/499 [00:00<00:00, 19932930.44it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 23831272.73it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 22795130.43it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 23831272.73it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 21183353.54it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 19972876.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 499/499 [00:00<00:00, 20929576.96it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 20763881.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 20763881.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 22550021.51it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 20763881.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 21620123.71it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 21845333.33it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 21620123.71it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 20763881.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 20164923.08it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 19972876.19it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 19239926.61it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 500/500 [00:00<00:00, 18558867.26it/s]\n",
      "Retrieving TaskDoc documents: 100%|██████████| 451/451 [00:00<00:00, 7247628.75it/s]\n"
     ]
    }
   ],
   "source": [
    "# Query in batches\n",
    "task_to_calc = {}\n",
    "batch_size = 500\n",
    "\n",
    "with MPRester(API_KEY) as mpr:\n",
    "    for i in range(0, len(structure_task_ids), batch_size):\n",
    "        batch = structure_task_ids[i:i+batch_size]\n",
    "        task_docs = mpr.tasks.search(\n",
    "            task_ids=batch,\n",
    "            fields=[\"task_id\", \"calc_type\"]\n",
    "        )\n",
    "        task_to_calc.update({doc.task_id: doc.calc_type for doc in task_docs})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7af4ea65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique calc_types found: {<CalcType.GGA_Structure_Optimization: 'GGA Structure Optimization'>, <CalcType.r2SCAN_Structure_Optimization: 'r2SCAN Structure Optimization'>, <CalcType.GGA_Static: 'GGA Static'>, <CalcType.GGA_U_Static: 'GGA+U Static'>, <CalcType.GGA_U_Structure_Optimization: 'GGA+U Structure Optimization'>, <CalcType.r2SCAN_Static: 'r2SCAN Static'>, <CalcType.SCAN_Structure_Optimization: 'SCAN Structure Optimization'>}\n",
      "Total: 7 different calculation types\n"
     ]
    }
   ],
   "source": [
    "unique_calc_types = set(task_to_calc[doc] for doc in task_to_calc)\n",
    "print(f\"Unique calc_types found: {unique_calc_types}\")\n",
    "print(f\"Total: {len(unique_calc_types)} different calculation types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a065202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Materials with GGA-optimized structures: 13528/28951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter for GGA-optimized structures only\n",
    "gga_materials = {}\n",
    "for icsd_id, data in selected_docs.items():\n",
    "    structure_task_ids = next(\n",
    "        (origin.task_id for origin in data['MP'].origins if origin.name == 'structure'),\n",
    "        None\n",
    "    )\n",
    "    \n",
    "    if structure_task_ids and task_to_calc.get(structure_task_ids) in ['GGA Structure Optimization', 'GGA Static']:\n",
    "        gga_materials[icsd_id] = data\n",
    "\n",
    "print(f\"Materials with GGA-optimized structures: {len(gga_materials)}/{len(selected_docs)}\")\n",
    "\n",
    "selected_docs = gga_materials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3203259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Convert MP objects to dictionaries\n",
    "selected_docs_serializable = {}\n",
    "for icsd_id, data in selected_docs.items():\n",
    "    selected_docs_serializable[icsd_id] = {\n",
    "        'MP': data['MP'].dict() if hasattr(data['MP'], 'dict') else data['MP'],\n",
    "        'ICSD': data['ICSD']\n",
    "    }\n",
    "\n",
    "# Save to JSON\n",
    "with open('theoretical_experimental_structures.json', 'w') as f:\n",
    "    json.dump(selected_docs_serializable, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ca46b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 13528 GGA materials to final_selection.txt\n"
     ]
    }
   ],
   "source": [
    "# Save MP ID to ICSD mapping for GGA materials\n",
    "with open('final_selection.txt', 'w') as f:\n",
    "    for icsd_id, data in gga_materials.items():\n",
    "        mpid = data['MP'].material_id\n",
    "        f.write(f\"{mpid}: {icsd_id}\\n\")\n",
    "\n",
    "print(f\"Saved {len(gga_materials)} GGA materials to final_selection.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ae5c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "repo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
